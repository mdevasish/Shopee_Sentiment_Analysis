{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review_id', 'review', 'rating'], dtype='object')\n",
      "train dimension:  (146811, 3)\n",
      "test dimension:  (60427, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('./Data/train.csv')\n",
    "test = pd.read_csv(\"./Data/test.csv\")\n",
    "\n",
    "print(train.columns)\n",
    "\n",
    "print(\"train dimension: \", train.shape)\n",
    "print(\"test dimension: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ga disappointed neat products .. Meletot Hilsn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rdtanya replace broken glass, broken chargernya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nyesel bngt dsni shopping antecedent photo mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sent a light blue suit goods ga want a refund</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pendants came with dents and scratches on its ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                             review  rating\n",
       "0          0  Ga disappointed neat products .. Meletot Hilsn...       1\n",
       "1          1    Rdtanya replace broken glass, broken chargernya       1\n",
       "2          2  Nyesel bngt dsni shopping antecedent photo mes...       1\n",
       "3          3      Sent a light blue suit goods ga want a refund       1\n",
       "4          4  Pendants came with dents and scratches on its ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rating'] = train['rating']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def tokenize(text, stop_set = False, lemma = False):\n",
    "    \n",
    "    # clean text\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'\\b(?:(?:https?|ftp)://)?\\w[\\w-]*(?:\\.[\\w-]+)+\\S*', ' ', text) # remove hyperlink,subs charact in the brackets\n",
    "    text = re.sub(\"[\\r\\n]\", ' ', text) # remove new line characters\n",
    "    #text = re.sub(r'[^\\w\\s]','',text)\n",
    "    text = text.strip() ## convert to lowercase split indv words\n",
    "    tknzr = TweetTokenizer()\n",
    "    tokens = tknzr.tokenize(text)\n",
    "    \n",
    "    # retain tokens with at least two words\n",
    "    tokens = [token for token in tokens if re.match(r'.*[a-z]{2,}.*', token)]\n",
    "    if stop_set != False:\n",
    "        tokens = [token for token in tokens if token not in stop_set]\n",
    "    \n",
    "    # lemmmatization - optional\n",
    "    if lemma != False:\n",
    "        tokens = [WordNetLemmatizer.lemmatize(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "# without lemmatization\n",
    "train['tokens'] = train['review'].map(lambda x: tokenize(x,lemma = False))\n",
    "test['tokens'] = test['review'].map(lambda x: tokenize(x,lemma = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Great danger, cool, motif and cantik2 jg model...</td>\n",
       "      <td>[great, danger, cool, motif, and, cantik, jg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>One of the shades don't fit well</td>\n",
       "      <td>[one, of, the, shades, don't, fit, well]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Very comfortable</td>\n",
       "      <td>[very, comfortable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fast delivery. Product expiry is on Dec 2022. ...</td>\n",
       "      <td>[fast, delivery, product, expiry, is, on, dec,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>it's sooooo cute! i like playing with the glit...</td>\n",
       "      <td>[it's, sooooo, cute, like, playing, with, the,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                             review  \\\n",
       "0          1  Great danger, cool, motif and cantik2 jg model...   \n",
       "1          2                   One of the shades don't fit well   \n",
       "2          3                                   Very comfortable   \n",
       "3          4  Fast delivery. Product expiry is on Dec 2022. ...   \n",
       "4          5  it's sooooo cute! i like playing with the glit...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [great, danger, cool, motif, and, cantik, jg, ...  \n",
       "1           [one, of, the, shades, don't, fit, well]  \n",
       "2                                [very, comfortable]  \n",
       "3  [fast, delivery, product, expiry, is, on, dec,...  \n",
       "4  [it's, sooooo, cute, like, playing, with, the,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(token_col):\n",
    "    \n",
    "    vocab = {}\n",
    "    for tokens in token_col:\n",
    "        for token in tokens:\n",
    "            vocab[token] = vocab.get(token, 0) + 1\n",
    "\n",
    "    return vocab\n",
    "\n",
    "train_vocab = build_vocab(train['tokens'])\n",
    "test_vocab = build_vocab(test['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': 84720,\n",
       " 'the': 84372,\n",
       " 'product': 57881,\n",
       " 'is': 54435,\n",
       " 'quality': 51159,\n",
       " 'very': 43967,\n",
       " 'delivery': 37393,\n",
       " 'to': 27963,\n",
       " 'of': 26641,\n",
       " 'and': 24112,\n",
       " 'not': 23210,\n",
       " 'seller': 22636,\n",
       " 'price': 21511,\n",
       " 'speed': 20582,\n",
       " 'excellent': 19950,\n",
       " 'but': 19541,\n",
       " 'awesome': 19138,\n",
       " 'fast': 18850,\n",
       " 'goods': 18296,\n",
       " 'for': 15000,\n",
       " 'in': 14973,\n",
       " 'it': 14711,\n",
       " 'value': 12230,\n",
       " 'response': 11470,\n",
       " 'order': 11016,\n",
       " 'nice': 10624,\n",
       " 'you': 10255,\n",
       " 'thank': 10145,\n",
       " 'thanks': 9095,\n",
       " 'that': 8504,\n",
       " 'with': 8465,\n",
       " 'service': 8262,\n",
       " 'this': 7966,\n",
       " 'like': 7937,\n",
       " 'was': 7311,\n",
       " 'also': 7119,\n",
       " 'original': 7107,\n",
       " 'other': 7103,\n",
       " 'ok': 6977,\n",
       " 'so': 6818,\n",
       " 'well': 6629,\n",
       " 'again': 6620,\n",
       " 'money': 6396,\n",
       " 'will': 6375,\n",
       " 'packaging': 6207,\n",
       " 'really': 6170,\n",
       " 'time': 6146,\n",
       " 'be': 5811,\n",
       " 'shop': 5646,\n",
       " 'its': 5560,\n",
       " 'his': 5545,\n",
       " 'my': 5541,\n",
       " 'are': 5534,\n",
       " 'buy': 5498,\n",
       " 'as': 5421,\n",
       " 'just': 5400,\n",
       " 'okay': 5338,\n",
       " 'color': 5129,\n",
       " 'cp': 5085,\n",
       " 'no': 4759,\n",
       " 'products': 4734,\n",
       " 'item': 4722,\n",
       " 'received': 4610,\n",
       " 'already': 4469,\n",
       " 'all': 4447,\n",
       " 'size': 4441,\n",
       " 'have': 4386,\n",
       " 'shipping': 4361,\n",
       " 'packing': 4329,\n",
       " 'too': 4299,\n",
       " 'kg': 4183,\n",
       " 'from': 4160,\n",
       " 'material': 4131,\n",
       " 'can': 4106,\n",
       " 'beautiful': 4072,\n",
       " 'there': 4063,\n",
       " 'long': 4021,\n",
       " 'tp': 3825,\n",
       " 'her': 3776,\n",
       " 'ga': 3745,\n",
       " 'because': 3697,\n",
       " 'on': 3675,\n",
       " 'ship': 3647,\n",
       " 'little': 3640,\n",
       " 'here': 3628,\n",
       " 'do': 3598,\n",
       " 'much': 3582,\n",
       " 'me': 3548,\n",
       " 'one': 3434,\n",
       " 'pretty': 3416,\n",
       " 'love': 3400,\n",
       " 'at': 3371,\n",
       " 'only': 3340,\n",
       " 'more': 3304,\n",
       " 'by': 3298,\n",
       " 'shipped': 3285,\n",
       " 'if': 3253,\n",
       " 'cheap': 3204,\n",
       " 'until': 3202,\n",
       " 'use': 3116,\n",
       " 'hopefully': 3080,\n",
       " 'sent': 3038,\n",
       " 'bgt': 2981,\n",
       " 'satisfied': 2923,\n",
       " 'has': 2822,\n",
       " 'small': 2813,\n",
       " 'up': 2788,\n",
       " 'next': 2708,\n",
       " 'stuff': 2699,\n",
       " 'same': 2697,\n",
       " 'less': 2687,\n",
       " 'always': 2678,\n",
       " 'yes': 2650,\n",
       " 'worth': 2640,\n",
       " 'merchandise': 2603,\n",
       " \"it's\": 2594,\n",
       " 'than': 2525,\n",
       " 'package': 2521,\n",
       " 'disappointed': 2520,\n",
       " 'still': 2515,\n",
       " 'store': 2489,\n",
       " 'fit': 2449,\n",
       " 'thin': 2431,\n",
       " 'ya': 2429,\n",
       " 'super': 2419,\n",
       " 'cepet': 2418,\n",
       " 'great': 2405,\n",
       " 'standard': 2392,\n",
       " 'bit': 2357,\n",
       " 'neat': 2310,\n",
       " 'new': 2285,\n",
       " 'according': 2219,\n",
       " 'items': 2207,\n",
       " 'out': 2204,\n",
       " 'first': 2183,\n",
       " 'steady': 2177,\n",
       " 'been': 2106,\n",
       " 'kak': 2097,\n",
       " 'friendly': 2095,\n",
       " 'condition': 2053,\n",
       " 'when': 2019,\n",
       " 'send': 2002,\n",
       " 'arrived': 1997,\n",
       " 'poor': 1963,\n",
       " 'who': 1938,\n",
       " 'prices': 1925,\n",
       " 'then': 1919,\n",
       " 'orders': 1905,\n",
       " 'quite': 1903,\n",
       " 'accommodating': 1898,\n",
       " 'try': 1865,\n",
       " 'safely': 1860,\n",
       " 'fabric': 1825,\n",
       " \"seller's\": 1823,\n",
       " 'want': 1822,\n",
       " 'anyway': 1817,\n",
       " 'does': 1808,\n",
       " 'accordance': 1800,\n",
       " 'cute': 1793,\n",
       " 'get': 1786,\n",
       " 'box': 1779,\n",
       " 'slow': 1769,\n",
       " 'free': 1767,\n",
       " 'shopping': 1733,\n",
       " 'ordered': 1731,\n",
       " 'picture': 1706,\n",
       " 'safe': 1675,\n",
       " 'quickly': 1653,\n",
       " 'alhamdulillah': 1653,\n",
       " 'recommended': 1627,\n",
       " 'come': 1623,\n",
       " 'bad': 1622,\n",
       " 'what': 1620,\n",
       " 'may': 1610,\n",
       " 'should': 1610,\n",
       " 'immediately': 1610,\n",
       " 'tq': 1605,\n",
       " 'deh': 1585,\n",
       " 'cool': 1573,\n",
       " 'overall': 1569,\n",
       " 'even': 1564,\n",
       " 'or': 1562,\n",
       " 'before': 1540,\n",
       " 'days': 1538,\n",
       " 'best': 1500,\n",
       " 'wrap': 1490,\n",
       " 'jg': 1486,\n",
       " 'soft': 1480,\n",
       " 'shopee': 1478,\n",
       " 'would': 1457,\n",
       " 'which': 1450,\n",
       " 'message': 1445,\n",
       " 'used': 1443,\n",
       " 'bag': 1443,\n",
       " 'wrong': 1426,\n",
       " 'bubble': 1425,\n",
       " 'gk': 1406,\n",
       " 'old': 1378,\n",
       " 'lah': 1364,\n",
       " 'different': 1358,\n",
       " 'some': 1342,\n",
       " 'big': 1330,\n",
       " 'well-packaged': 1325,\n",
       " 'reply': 1323,\n",
       " 'black': 1321,\n",
       " 'pack': 1315,\n",
       " 'please': 1287,\n",
       " 'day': 1273,\n",
       " 'yet': 1260,\n",
       " 'god': 1260,\n",
       " 'wear': 1255,\n",
       " 'make': 1249,\n",
       " 'he': 1204,\n",
       " 'certainly': 1195,\n",
       " 'times': 1172,\n",
       " 'after': 1171,\n",
       " 'lg': 1164,\n",
       " 'many': 1161,\n",
       " 'thick': 1161,\n",
       " 'did': 1158,\n",
       " 'star': 1154,\n",
       " 'suitable': 1143,\n",
       " 'neatly': 1138,\n",
       " 'passable': 1123,\n",
       " 'standards': 1116,\n",
       " 'durable': 1109,\n",
       " 'udh': 1109,\n",
       " 'another': 1104,\n",
       " 'appropriate': 1104,\n",
       " 'enough': 1103,\n",
       " 'broken': 1098,\n",
       " 'complete': 1092,\n",
       " 'affordable': 1092,\n",
       " 'image': 1090,\n",
       " 'dah': 1088,\n",
       " 'delivered': 1085,\n",
       " 'clothes': 1083,\n",
       " 'chat': 1078,\n",
       " 'bought': 1076,\n",
       " 'wait': 1072,\n",
       " 'quick': 1069,\n",
       " 'any': 1065,\n",
       " 'know': 1057,\n",
       " 'pesen': 1056,\n",
       " 'jd': 1053,\n",
       " 'right': 1052,\n",
       " 'how': 1046,\n",
       " 'had': 1045,\n",
       " 'lot': 1036,\n",
       " 'hope': 1026,\n",
       " 'we': 1014,\n",
       " 'brg': 1014,\n",
       " 'carefully': 1012,\n",
       " 'services': 1002,\n",
       " 'happy': 1001,\n",
       " \"ship's\": 1001,\n",
       " 'comfortable': 1000,\n",
       " 'sy': 997,\n",
       " 'put': 990,\n",
       " 'plastic': 989,\n",
       " 'sure': 988,\n",
       " 'rather': 983,\n",
       " 'purchase': 981,\n",
       " 'back': 974,\n",
       " 'damaged': 969,\n",
       " 'see': 962,\n",
       " 'although': 958,\n",
       " 'sorry': 957,\n",
       " 'slightly': 952,\n",
       " 'nyampe': 951,\n",
       " 'two': 947,\n",
       " 'better': 945,\n",
       " 'white': 937,\n",
       " 'expected': 925,\n",
       " 'came': 909,\n",
       " 'now': 906,\n",
       " 'po': 905,\n",
       " 'think': 904,\n",
       " 'were': 901,\n",
       " 'sellers': 893,\n",
       " 'shoes': 873,\n",
       " 'real': 872,\n",
       " 'your': 859,\n",
       " 'stars': 854,\n",
       " 'pants': 851,\n",
       " 'packaged': 851,\n",
       " 'they': 850,\n",
       " 'case': 848,\n",
       " 'unfortunately': 846,\n",
       " 'ung': 840,\n",
       " 'definitely': 840,\n",
       " 'customer': 835,\n",
       " 'pink': 833,\n",
       " 'colors': 831,\n",
       " 'fitting': 822,\n",
       " 'why': 816,\n",
       " 'ny': 815,\n",
       " 'full': 814,\n",
       " 'tpi': 809,\n",
       " 'top': 808,\n",
       " 'ko': 803,\n",
       " 'sis': 803,\n",
       " 'check': 802,\n",
       " 'shirt': 795,\n",
       " 'look': 789,\n",
       " 'aja': 788,\n",
       " 'match': 787,\n",
       " 'easy': 787,\n",
       " 'gift': 787,\n",
       " 'blue': 786,\n",
       " 'sdh': 783,\n",
       " 'got': 782,\n",
       " 'description': 776,\n",
       " 'carrier': 768,\n",
       " 'though': 759,\n",
       " 'wrote': 758,\n",
       " 'fabulous': 757,\n",
       " 'an': 735,\n",
       " 'given': 733,\n",
       " 'once': 732,\n",
       " 'turns': 731,\n",
       " 'yaa': 729,\n",
       " 'packed': 724,\n",
       " 'longer': 724,\n",
       " 'let': 724,\n",
       " 'red': 720,\n",
       " 'need': 719,\n",
       " 'customers': 715,\n",
       " 'courier': 714,\n",
       " 'secure': 714,\n",
       " 'wrapped': 711,\n",
       " 'subscription': 707,\n",
       " 'without': 705,\n",
       " 'mm': 704,\n",
       " 'using': 697,\n",
       " 'about': 694,\n",
       " 'corresponding': 693,\n",
       " 'soon': 691,\n",
       " 'yg': 687,\n",
       " 'continue': 687,\n",
       " 'could': 686,\n",
       " 'materials': 685,\n",
       " 'recomended': 685,\n",
       " 'repeat': 679,\n",
       " 'subscriptions': 678,\n",
       " 'ori': 675,\n",
       " 'second': 674,\n",
       " 'take': 670,\n",
       " 'receive': 664,\n",
       " 'she': 662,\n",
       " 'ask': 661,\n",
       " 'stores': 660,\n",
       " 'date': 652,\n",
       " 'light': 643,\n",
       " 'success': 642,\n",
       " 'support': 640,\n",
       " 'recommend': 633,\n",
       " 'never': 632,\n",
       " 'cover': 630,\n",
       " 'over': 630,\n",
       " 'cheaper': 629,\n",
       " 'looks': 624,\n",
       " 'work': 621,\n",
       " 'bonus': 619,\n",
       " 'somewhat': 617,\n",
       " 'those': 615,\n",
       " 'dc': 615,\n",
       " 'cpt': 612,\n",
       " 'late': 612,\n",
       " 'tried': 610,\n",
       " 'smooth': 609,\n",
       " 'give': 608,\n",
       " 'hard': 608,\n",
       " 'short': 605,\n",
       " 'photo': 602,\n",
       " 'arrive': 601,\n",
       " 'cloth': 597,\n",
       " 'sale': 595,\n",
       " 'baby': 595,\n",
       " 'said': 593,\n",
       " 'problem': 593,\n",
       " 'fine': 591,\n",
       " 'am': 591,\n",
       " 'open': 589,\n",
       " 'gan': 586,\n",
       " 'gpp': 585,\n",
       " 'comes': 584,\n",
       " 'say': 583,\n",
       " 'works': 583,\n",
       " 'instead': 582,\n",
       " 'create': 580,\n",
       " 'yung': 576,\n",
       " 'cuman': 575,\n",
       " 'values': 575,\n",
       " 'loved': 574,\n",
       " 'rich': 570,\n",
       " 'sensitive': 569,\n",
       " 'buying': 563,\n",
       " 'refund': 560,\n",
       " 'mouth': 560,\n",
       " 'hehe': 560,\n",
       " 'dr': 557,\n",
       " 'baguss': 555,\n",
       " 'exactly': 552,\n",
       " 'must': 550,\n",
       " 'ka': 548,\n",
       " 'off': 548,\n",
       " 'thx': 547,\n",
       " 'shops': 544,\n",
       " 'packingnya': 544,\n",
       " 'klo': 542,\n",
       " 'smell': 536,\n",
       " 'people': 534,\n",
       " 'home': 534,\n",
       " 'things': 533,\n",
       " 'yesterday': 532,\n",
       " 'cm': 525,\n",
       " 'week': 520,\n",
       " 'children': 519,\n",
       " 'transport': 516,\n",
       " 'everything': 515,\n",
       " 'damage': 512,\n",
       " 'took': 511,\n",
       " 'process': 511,\n",
       " 'today': 510,\n",
       " 'tebel': 509,\n",
       " 'asked': 501,\n",
       " 'ni': 501,\n",
       " 'na': 495,\n",
       " 'them': 494,\n",
       " 'taste': 492,\n",
       " 'responsive': 492,\n",
       " 'both': 491,\n",
       " 'their': 488,\n",
       " 'dateng': 488,\n",
       " 'going': 486,\n",
       " 'large': 486,\n",
       " 'son': 483,\n",
       " 'go': 483,\n",
       " 'tasty': 482,\n",
       " 'set': 482,\n",
       " 'pas': 481,\n",
       " 'dapet': 480,\n",
       " 'krn': 480,\n",
       " 'boss': 479,\n",
       " 'sensitivity': 479,\n",
       " 'reasonable': 478,\n",
       " 'pict': 478,\n",
       " 'stock': 477,\n",
       " 'change': 476,\n",
       " 'sp': 472,\n",
       " 'sad': 469,\n",
       " 'thankyou': 469,\n",
       " 'dg': 467,\n",
       " 'directly': 466,\n",
       " 'strong': 466,\n",
       " 'later': 464,\n",
       " 'mask': 463,\n",
       " 'line': 462,\n",
       " 'praise': 462,\n",
       " 'skin': 461,\n",
       " 'provided': 459,\n",
       " 'fair': 457,\n",
       " 'dear': 456,\n",
       " 'nyesel': 455,\n",
       " 'funny': 455,\n",
       " 'cardboard': 454,\n",
       " 'satisfactory': 454,\n",
       " 'feel': 454,\n",
       " 'tidy': 451,\n",
       " 'torn': 450,\n",
       " 'mksh': 449,\n",
       " 'pay': 449,\n",
       " 'keep': 447,\n",
       " 'far': 447,\n",
       " 'design': 446,\n",
       " 'faster': 446,\n",
       " 'high': 444,\n",
       " 'actually': 439,\n",
       " 'delicious': 438,\n",
       " 'dented': 437,\n",
       " 'add': 437,\n",
       " 'him': 436,\n",
       " 'expensive': 434,\n",
       " 'green': 434,\n",
       " 'water': 431,\n",
       " 'dress': 431,\n",
       " 'into': 428,\n",
       " 'serves': 428,\n",
       " 'bottle': 428,\n",
       " 'expectations': 427,\n",
       " 'done': 426,\n",
       " 'smaller': 425,\n",
       " 'amount': 424,\n",
       " 'disappointing': 424,\n",
       " 'photos': 423,\n",
       " 'made': 421,\n",
       " 'others': 420,\n",
       " 'trimakasih': 420,\n",
       " 'bgus': 419,\n",
       " 'turned': 417,\n",
       " 'sm': 415,\n",
       " 'each': 414,\n",
       " 'battery': 413,\n",
       " 'ad': 410,\n",
       " 'cut': 408,\n",
       " 'properly': 407,\n",
       " 'model': 407,\n",
       " 'amc': 407,\n",
       " 'defective': 406,\n",
       " 'sir': 405,\n",
       " 'kk': 404,\n",
       " 'being': 403,\n",
       " 'request': 403,\n",
       " 'pictures': 402,\n",
       " 'finally': 402,\n",
       " 'xl': 402,\n",
       " 'cream': 400,\n",
       " 'loves': 400,\n",
       " 'inside': 397,\n",
       " 'most': 396,\n",
       " 'landed': 396,\n",
       " 'return': 395,\n",
       " 'future': 395,\n",
       " 'loose': 395,\n",
       " 'fits': 394,\n",
       " 'forward': 393,\n",
       " 'naman': 390,\n",
       " 'hot': 390,\n",
       " 'where': 387,\n",
       " 'such': 387,\n",
       " 'perfect': 385,\n",
       " 'guns': 385,\n",
       " 'way': 383,\n",
       " 'low': 383,\n",
       " 'sya': 383,\n",
       " 'plus': 382,\n",
       " '2nd': 382,\n",
       " 'thought': 381,\n",
       " 'baik': 381,\n",
       " 'dh': 380,\n",
       " 'restaurant': 377,\n",
       " 'buyer': 376,\n",
       " 'phone': 375,\n",
       " 'almost': 374,\n",
       " 'smoga': 373,\n",
       " 'last': 372,\n",
       " 'bagus': 372,\n",
       " 'few': 369,\n",
       " 'thing': 368,\n",
       " 'eat': 368,\n",
       " 'through': 366,\n",
       " 'bs': 365,\n",
       " 'missing': 365,\n",
       " 'bangett': 365,\n",
       " 'form': 364,\n",
       " 'every': 363,\n",
       " 'normal': 363,\n",
       " 'empty': 361,\n",
       " 'la': 352,\n",
       " 'sold': 351,\n",
       " 'lng': 351,\n",
       " 'selling': 348,\n",
       " 'kirain': 347,\n",
       " 'waiting': 347,\n",
       " 'sound': 346,\n",
       " 'careful': 346,\n",
       " 'body': 346,\n",
       " 'book': 346,\n",
       " 'bags': 345,\n",
       " 'these': 344,\n",
       " 'je': 343,\n",
       " 'dtg': 343,\n",
       " 'broke': 343,\n",
       " 'clear': 342,\n",
       " 'confirmation': 342,\n",
       " 'yaaa': 342,\n",
       " 'course': 342,\n",
       " 'cost': 341,\n",
       " 'nothing': 340,\n",
       " 'pokonya': 340,\n",
       " 'results': 339,\n",
       " 'dd': 339,\n",
       " 'own': 338,\n",
       " 'number': 338,\n",
       " 'dirty': 337,\n",
       " 'part': 336,\n",
       " 'yellow': 336,\n",
       " 'glue': 335,\n",
       " 'answer': 335,\n",
       " 'however': 335,\n",
       " 'eh': 333,\n",
       " 'hours': 329,\n",
       " '2an': 329,\n",
       " 'while': 329,\n",
       " 'dark': 329,\n",
       " 'flash': 329,\n",
       " 'side': 328,\n",
       " 'tight': 328,\n",
       " 'maybe': 328,\n",
       " 'mudah': 328,\n",
       " 'repurchase': 328,\n",
       " 'glass': 327,\n",
       " 'subscribed': 327,\n",
       " 'afternoon': 325,\n",
       " 'kind': 324,\n",
       " 'job': 324,\n",
       " 'dong': 321,\n",
       " 'hair': 321,\n",
       " 'baht': 319,\n",
       " 'mantul': 319,\n",
       " 'liked': 318,\n",
       " 'purchased': 318,\n",
       " 'working': 318,\n",
       " 'correct': 318,\n",
       " 'hand': 318,\n",
       " 'several': 317,\n",
       " 'kok': 317,\n",
       " 'shipment': 317,\n",
       " 'oh': 317,\n",
       " 'paper': 316,\n",
       " 'pieces': 316,\n",
       " 'brown': 316,\n",
       " 'due': 315,\n",
       " 'highly': 315,\n",
       " 'texture': 314,\n",
       " 'interchangeable': 314,\n",
       " 'function': 313,\n",
       " 'bangettt': 313,\n",
       " 'contents': 312,\n",
       " 'outside': 312,\n",
       " 'opened': 312,\n",
       " 'coming': 312,\n",
       " 'fortunately': 311,\n",
       " 'pro': 310,\n",
       " 'close': 310,\n",
       " 'admin': 310,\n",
       " 'ready': 309,\n",
       " 'sending': 308,\n",
       " 'code': 307,\n",
       " 'shape': 307,\n",
       " 'genuine': 307,\n",
       " 'ugly': 306,\n",
       " 'disappoint': 306,\n",
       " 'respond': 305,\n",
       " 'during': 305,\n",
       " 'easily': 304,\n",
       " 'paid': 304,\n",
       " 'gray': 303,\n",
       " 'aq': 303,\n",
       " 'seems': 302,\n",
       " 'face': 301,\n",
       " 'post': 301,\n",
       " 'discount': 301,\n",
       " 'review': 301,\n",
       " 'together': 300,\n",
       " 'regret': 300,\n",
       " 'since': 299,\n",
       " 'around': 299,\n",
       " 'sell': 298,\n",
       " 'bright': 297,\n",
       " 'compared': 297,\n",
       " 'three': 296,\n",
       " 'gak': 294,\n",
       " 'place': 294,\n",
       " 'note': 293,\n",
       " 'usual': 293,\n",
       " 'temporary': 293,\n",
       " 'bounced': 293,\n",
       " 'pic': 292,\n",
       " 'makasi': 290,\n",
       " 'month': 289,\n",
       " 'pcs': 288,\n",
       " 'messages': 287,\n",
       " 'lovely': 287,\n",
       " 'difficult': 286,\n",
       " 'buyers': 286,\n",
       " 'sma': 284,\n",
       " 'brother': 284,\n",
       " 'enthusiastic': 282,\n",
       " 'weeks': 280,\n",
       " 'available': 280,\n",
       " 'sellernya': 280,\n",
       " 'type': 278,\n",
       " 'smpai': 278,\n",
       " 'direct': 276,\n",
       " 'ever': 276,\n",
       " 'milk': 276,\n",
       " 'within': 276,\n",
       " 'likes': 276,\n",
       " 'deal': 275,\n",
       " 'brand': 273,\n",
       " 'charge': 273,\n",
       " 'smpe': 272,\n",
       " 'pdhl': 271,\n",
       " 'mah': 270,\n",
       " 'boxes': 270,\n",
       " 'sip': 270,\n",
       " 'stick': 269,\n",
       " 'satisfying': 269,\n",
       " 'substantially': 268,\n",
       " 'child': 268,\n",
       " 'rope': 264,\n",
       " 'wearing': 264,\n",
       " 'cepat': 264,\n",
       " 'dry': 263,\n",
       " 'something': 262,\n",
       " 'china': 262,\n",
       " 'transaction': 262,\n",
       " 'bngt': 260,\n",
       " 'jdi': 260,\n",
       " 'luck': 260,\n",
       " 'fabrics': 259,\n",
       " 'house': 258,\n",
       " 'screen': 258,\n",
       " 'uda': 257,\n",
       " 'help': 257,\n",
       " 'sukaa': 257,\n",
       " 'often': 256,\n",
       " 'down': 254,\n",
       " 'mantab': 254,\n",
       " 'suit': 253,\n",
       " 'flame': 253,\n",
       " 'despite': 253,\n",
       " 'lgi': 252,\n",
       " 'purple': 252,\n",
       " 'continued': 252,\n",
       " 'tell': 251,\n",
       " 'wrna': 251,\n",
       " 'piece': 250,\n",
       " 'bener': 250,\n",
       " 'heavy': 250,\n",
       " 'pesenan': 250,\n",
       " 'buildup': 249,\n",
       " 'promo': 249,\n",
       " 'online': 248,\n",
       " 'hrga': 248,\n",
       " 'useful': 248,\n",
       " 'successfully': 247,\n",
       " 'relatively': 247,\n",
       " 'mandate': 246,\n",
       " 'bagussss': 246,\n",
       " 'trusted': 245,\n",
       " 'realpict': 244,\n",
       " 'understand': 244,\n",
       " 'find': 243,\n",
       " 'barang': 243,\n",
       " 'wide': 243,\n",
       " 'tetep': 243,\n",
       " 'yah': 242,\n",
       " 'away': 242,\n",
       " 'morbidly': 241,\n",
       " 'end': 241,\n",
       " 'nya': 241,\n",
       " 'left': 240,\n",
       " 'choose': 239,\n",
       " \"i've\": 237,\n",
       " 'important': 237,\n",
       " 'cotton': 237,\n",
       " 'arriving': 237,\n",
       " 'deliver': 236,\n",
       " 'parcel': 235,\n",
       " 'stitches': 234,\n",
       " 'till': 234,\n",
       " 'read': 233,\n",
       " 'gini': 232,\n",
       " 'sales': 232,\n",
       " 'blessing': 232,\n",
       " 'fragrant': 231,\n",
       " 'night': 231,\n",
       " 'anything': 231,\n",
       " 'matches': 231,\n",
       " 'lid': 230,\n",
       " 'oke': 230,\n",
       " 'rubber': 229,\n",
       " 'lack': 229,\n",
       " 'bless': 229,\n",
       " 'hold': 228,\n",
       " 'successful': 228,\n",
       " 'fragrance': 228,\n",
       " 'attitude': 227,\n",
       " 'call': 227,\n",
       " 'general': 227,\n",
       " 'intact': 227,\n",
       " 'morning': 227,\n",
       " 'usually': 226,\n",
       " 'dents': 225,\n",
       " 'kaka': 225,\n",
       " 'packages': 224,\n",
       " 'hour': 224,\n",
       " 'expect': 223,\n",
       " 'bnget': 222,\n",
       " 'sempet': 222,\n",
       " 'lbh': 221,\n",
       " 'us': 220,\n",
       " 'contact': 220,\n",
       " 'whereas': 219,\n",
       " 'motive': 218,\n",
       " 'stitching': 218,\n",
       " 'weve': 217,\n",
       " 'socks': 217,\n",
       " 'lang': 216,\n",
       " 'gifts': 216,\n",
       " 'abroad': 216,\n",
       " 'continues': 216,\n",
       " 'length': 215,\n",
       " 'front': 215,\n",
       " 'rest': 214,\n",
       " 'transportation': 214,\n",
       " 'sweet': 213,\n",
       " \"that's\": 212,\n",
       " 'finished': 212,\n",
       " 'hell': 212,\n",
       " \"there's\": 212,\n",
       " 'loss': 212,\n",
       " 'either': 212,\n",
       " 'difference': 211,\n",
       " 'sgt': 211,\n",
       " 'oil': 210,\n",
       " 'told': 209,\n",
       " 'per': 209,\n",
       " 'true': 209,\n",
       " 'tu': 208,\n",
       " 'our': 208,\n",
       " 'round': 207,\n",
       " 'shown': 206,\n",
       " 'mother': 206,\n",
       " 'considered': 206,\n",
       " 'defects': 206,\n",
       " 'break': 205,\n",
       " 'colour': 204,\n",
       " 'brush': 204,\n",
       " 'friends': 204,\n",
       " 'jga': 204,\n",
       " 'skirt': 204,\n",
       " 'anymore': 203,\n",
       " 'express': 203,\n",
       " 'legit': 203,\n",
       " 'cushioning': 202,\n",
       " 'brang': 201,\n",
       " 'below': 200,\n",
       " 'advice': 200,\n",
       " 'added': 200,\n",
       " 'sister': 200,\n",
       " 'smoothly': 200,\n",
       " 'im': 199,\n",
       " 'weight': 199,\n",
       " 'play': 199,\n",
       " 'trs': 199,\n",
       " 'under': 199,\n",
       " 'tomorrow': 199,\n",
       " 'heck': 198,\n",
       " 'looking': 198,\n",
       " 'actual': 198,\n",
       " 'guess': 198,\n",
       " 'rekomended': 198,\n",
       " 'sukaaa': 198,\n",
       " 'gave': 197,\n",
       " 'seams': 197,\n",
       " 'head': 197,\n",
       " 'lights': 197,\n",
       " 'statement': 196,\n",
       " 'models': 196,\n",
       " 'sticky': 196,\n",
       " 'double': 195,\n",
       " 'test': 195,\n",
       " 'functioning': 195,\n",
       " 'banget': 195,\n",
       " 'business': 194,\n",
       " 'reached': 194,\n",
       " 'trust': 193,\n",
       " 'sukaaaa': 193,\n",
       " 'terrible': 192,\n",
       " 'able': 192,\n",
       " 'solid': 192,\n",
       " 'power': 191,\n",
       " 'dont': 191,\n",
       " 'increase': 191,\n",
       " 'umpteenth': 191,\n",
       " 'aga': 190,\n",
       " 'sampai': 190,\n",
       " 'sa': 189,\n",
       " 'willing': 189,\n",
       " 'motif': 188,\n",
       " 'smallness': 188,\n",
       " 'tau': 188,\n",
       " 'da': 188,\n",
       " 'bigger': 187,\n",
       " 'doang': 187,\n",
       " 'keeping': 187,\n",
       " 'lost': 186,\n",
       " 'year': 186,\n",
       " 'sampenya': 186,\n",
       " 'pleasant': 186,\n",
       " 'cable': 185,\n",
       " 'correspond': 185,\n",
       " 'kids': 185,\n",
       " 'extra': 185,\n",
       " \"i'll\": 185,\n",
       " 'owner': 185,\n",
       " 'dlu': 185,\n",
       " 'mmg': 185,\n",
       " 'distinguished': 185,\n",
       " 'sandals': 184,\n",
       " 'takes': 184,\n",
       " 'kayak': 183,\n",
       " 'zipper': 183,\n",
       " 'care': 183,\n",
       " 'expedition': 183,\n",
       " 'mcm': 183,\n",
       " 'heat': 183,\n",
       " 'suka': 183,\n",
       " 'ah': 182,\n",
       " 'severe': 182,\n",
       " 'feels': 182,\n",
       " 'accordingly': 182,\n",
       " 'acceptable': 182,\n",
       " 'clean': 181,\n",
       " 'overseas': 181,\n",
       " 'min': 181,\n",
       " 'packs': 181,\n",
       " 'nicely': 181,\n",
       " 'waste': 180,\n",
       " 'pattern': 180,\n",
       " 'watch': 180,\n",
       " 'generally': 180,\n",
       " 'unlike': 180,\n",
       " 'dent': 180,\n",
       " 'period': 179,\n",
       " 'hands': 179,\n",
       " 'nk': 179,\n",
       " 'food': 179,\n",
       " 'rough': 179,\n",
       " 'expectation': 178,\n",
       " 'improved': 178,\n",
       " 'parts': 178,\n",
       " 'purchasing': 178,\n",
       " 'smua': 178,\n",
       " 'oder': 178,\n",
       " 'sewing': 178,\n",
       " 'card': 178,\n",
       " 'fake': 177,\n",
       " 'regular': 177,\n",
       " 'ordinary': 177,\n",
       " 'inexpensive': 177,\n",
       " 'hehehe': 177,\n",
       " 'hole': 176,\n",
       " 'packingan': 176,\n",
       " 'wash': 176,\n",
       " 'bgs': 176,\n",
       " 'improve': 176,\n",
       " 'nerawang': 176,\n",
       " 'shoe': 175,\n",
       " 'wish': 175,\n",
       " 'machine': 175,\n",
       " 'indeed': 175,\n",
       " 'receipt': 174,\n",
       " 'name': 174,\n",
       " 'pa': 174,\n",
       " 'update': 174,\n",
       " 'extremely': 174,\n",
       " 'ng': 173,\n",
       " 'gold': 173,\n",
       " 'defect': 173,\n",
       " 'responsible': 173,\n",
       " 'tested': 173,\n",
       " 'krna': 173,\n",
       " 'foot': 172,\n",
       " 'charger': 172,\n",
       " 'similar': 172,\n",
       " 'result': 172,\n",
       " 'okee': 172,\n",
       " 'cust': 171,\n",
       " 'especially': 171,\n",
       " 'custom': 171,\n",
       " 'mksih': 171,\n",
       " 'sukak': 171,\n",
       " 'hp': 170,\n",
       " 'sizes': 170,\n",
       " 'replaced': 170,\n",
       " 'charging': 170,\n",
       " 'straight': 170,\n",
       " 'trying': 170,\n",
       " 'fan': 170,\n",
       " 'exp': 170,\n",
       " 'fall': 169,\n",
       " 'push': 169,\n",
       " 'rate': 169,\n",
       " 'tapi': 169,\n",
       " 'nyampenya': 169,\n",
       " 'simple': 168,\n",
       " 'navy': 168,\n",
       " 'probably': 168,\n",
       " 'bottom': 168,\n",
       " 'jne': 168,\n",
       " 'untried': 168,\n",
       " 'rapid': 168,\n",
       " 'described': 167,\n",
       " 'life': 167,\n",
       " 'information': 167,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(train_vocab.items(), key=lambda item: item[1],reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "news_path = './pretrained models/GoogleNews-vectors-negative300.bin'\n",
    "embeddings_index = KeyedVectors.load_word2vec_format(news_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def check_coverage(vocab,embedding):    \n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in vocab:\n",
    "        if word in embedding:\n",
    "            k += vocab[word]\n",
    "        else:\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "    return sorted_x\n",
    "not_found_vocab = check_coverage(train_vocab, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['to','of','and', 'bgt', 'sdh', 'udg', 'shopee']\n",
    "\n",
    "replace_dict = {'cepet':'fast','pesen':'order','dah':'bye','lg':'again','ung':'rotten','nyampe':'arrived','yg':'which','cuman':'only',\n",
    "'klo':'if','packingnya':'packing','gpp':'no problem','thx':'thanks','dapet':'get it','krn':'because','baguss':'good','gan':'bro',\n",
    "'dateng':'come','pas':'just right','nyesel':'sorry','mksh':'thank you','trimakasih':'thank you','bgus':'great','smoga':'i hope',\n",
    "'naman':'name','kirain':'i think','sya':'yes','pokoknya':'anyway','kok':'really','mantul':'really good','bangett':'really',\n",
    "'makasi':'thanks','dong':'please','sellernya':'seller','gak':'no','uda':'already','bangettt':'already','tetep':'still','pesenan':'order',\n",
    "'mudah2an':'i hope','smpai':'till','mah':'expensive','lgi':'again','lbh':'more','bagussss':'good','mantab':'steady','sukaa':'like',\n",
    "'jga':'also','bnget':'really','kaka':'written','meletot':'erupted','rdtanya' : 'he asked','chargernya':'charger','dsni':'here',\n",
    "'originalya':'original','jg':'too','deh':'okay','sdh':'already','tpi':'but','pokonya':'anyway','lah':'la','reallyt':'really',\n",
    "'sma':'school','orderan':'orders','wrna':'color','againi':'again','kak':'sis','rekomended':'recommended','kayak':'like',\n",
    "'blanja':'spend','likea':'like','becausea':'because','dlu':'previous','tau':'know','barang':'goods','dtng':'come','datang':'come',\n",
    "'bnyk': 'a lot','mantep':'awesome','swhich':'which','banget':'really','goodssss':'goods','rada':'rather','packagingnya':'packaging',\n",
    "'skrg':'now','pngiriman':'delivery','goodsss':'goods','prev':'previous','kan':'right','kek':'grandpa','lahh':'','lah':'','engga':'no',\n",
    "'makasih':'thank you','ordernya ':'orders','paketan':'package','mantapp':'really','ngecewain':'disappointed','pengirimanya':'sender',\n",
    "'bagus':'nice','comenya':'come','segini':'this much','knp':'why','bener':'right','kasi':'give','anak':'child','baik':'good','sukaa':'like',\n",
    "'likeaaa':'like','bangeet':'really','brgnya':'how come','ngk':'presume','lagi':'again','lagii':'again','hrg':'price','harga':'price',\n",
    "'penyok':'dent','penyok2':'dent','barangny':'goods','thanksi':'thanks','produk':'product','likeaaaaa':'like','murahhh':'cheap',\n",
    "'terimaksih':'thanks','ownernya':'owner','thankss':'thanks','gercep':'speed','casenya':'case','kakk':'sis','dteng':'come',\n",
    "'puasssss':'satisfied','masi':'still','sekali':'once','gapernah':'never','balikin':'return it','ancur':'broken','nyobain':'try it',\n",
    "'bangat':'really','nyangka':'suspect','sekalii':'once','sekaliii':'once','sekaliiii':'once','sampaii':'arrive','barangnyaa':'goods',\n",
    "'jaitannya':'linkage','nyari':'looking for it','bangeett':'really','disiniii':'here','abcdefghijklmnopqrstuvwxyz':'','priduk':'product',\n",
    "'baguuuuuuus':'nice','allhamdulilah':'','mantaffffffffffffffff':'excellent','sekaliiiii':'once','ambilis':'take it','parahhh':'severe','Ingkan':'want',\n",
    "'alhamdulillah':'','tq':'thanks'}\n",
    "\n",
    "def clean_token(tokens, remove_list, re_dict):\n",
    "    tokens = [token for token in tokens if token not in remove_list]\n",
    "    tokens = [re_dict[token] if token in re_dict else token for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "train['clean_tokens'] = train['tokens'].map(lambda x: clean_token(x, to_remove, replace_dict))\n",
    "test['clean_tokens'] = test['tokens'].map(lambda x: clean_token(x, to_remove, replace_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous run\n",
    "train_vocab = build_vocab(train['clean_tokens'])\n",
    "test_vocab = build_vocab(test['clean_tokens'])\n",
    "\n",
    "not_found_vocab = check_coverage(train_vocab, embeddings_index)\n",
    "not_found_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_vocab.sort(key=lambda tup: tup[1],reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_mean(tokens, embedding):\n",
    "    \n",
    "    e_values = []\n",
    "    e_values = [embedding[token] for token in tokens if token in embedding]\n",
    "    \n",
    "    if len(e_values) > 0:\n",
    "        return np.mean(np.array(e_values), axis=0)\n",
    "    else:\n",
    "        return np.zeros(300)\n",
    "      \n",
    "X = np.vstack(train['clean_tokens'].apply(lambda x: doc_mean(x, embeddings_index)))\n",
    "X_1 = np.vstack(test['clean_tokens'].apply(lambda x: doc_mean(x, embeddings_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['rating'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, tree, ensemble, metrics, model_selection, exceptions\n",
    "\n",
    "\n",
    "def print_score(y_true, y_pred):\n",
    "    print('macro_accuracy : ', metrics.accuracy_score(y_true, y_pred))\n",
    "    print('ave macro precision : ', metrics.precision_score(y_true, y_pred, average='macro', pos_label=1, sample_weight=None))\n",
    "    print('macro_recall : ', metrics.recall_score(y_true, y_pred, labels=None, pos_label=1, average='macro', sample_weight=None))\n",
    "    print('macro_F1 : ', metrics.f1_score(y_true, y_pred, labels=None, pos_label=1, average='macro', sample_weight=None))\n",
    "    \n",
    "    print('micro_ave precision : ', metrics.precision_score(y_true, y_pred, average='micro', pos_label=1, sample_weight=None))\n",
    "    print('micro_recall : ', metrics.recall_score(y_true, y_pred, labels=None, pos_label=1, average='micro', sample_weight=None))\n",
    "    print('micro_F1 : ', metrics.f1_score(y_true, y_pred, labels=None, pos_label=1, average='micro', sample_weight=None))\n",
    "    print('weighted_precision : ', metrics.precision_score(y_true, y_pred, average='weighted', pos_label=1, sample_weight=None))\n",
    "    print('weighted_recall : ', metrics.recall_score(y_true, y_pred, labels=None, pos_label=1, average='weighted', sample_weight=None))\n",
    "    print('weighted_F1 : ', metrics.f1_score(y_true, y_pred, labels=None, pos_label=1, average='weighted', sample_weight=None))\n",
    "    \n",
    "# train-test split\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size = 0.8, random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "param = {'booster': \"gblinear\", \n",
    "        'objective': \"reg:squarederror\", \n",
    "        'lambda': 0.1, \n",
    "        'alpha': 0}\n",
    "num_round = 15 # the number of training iterations\n",
    "\n",
    "# bst = GridSearchCV()\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bst.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds = [int(a+1+0.4) if a > 3 else int(a+1-0.4) for a in preds]\n",
    "best_preds = np.clip(np.round(best_preds),1,5)\n",
    "print_score(y_val, best_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
