{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import emot\n",
    "import json\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import pickle\n",
    "import nltk\n",
    "import gensim\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "EMOTICONS = emot.EMOTICONS\n",
    "\n",
    "stopwords = ['she','the','is','to','of','a','i','for','in','it','you','with','that','this','was','so','will','be','my',\n",
    "             'his','as','are','its','cp','have','from','there','tp','her','on','ga','at','by','if','has','me','d','does','he',\n",
    "             'jd','we','your','they','here',\"i'm\",'aja','an','let','u','me','am','their']\n",
    "\n",
    "mappings = {'cepet':'fast','pesen':'order','dah':'bye','lg':'again','ung':'rotten','nyampe':'arrived','yg':'which','cuman':'only',\n",
    "'klo':'if','packingnya':'packing','gpp':'no problem','thx':'thanks','dapet':'get it','krn':'because','baguss':'good','gan':'bro',\n",
    "'dateng':'come','pas':'just right','nyesel':'sorry','mksh':'thank you','trimakasih':'thank you','bgus':'great','smoga':'i hope',\n",
    "'naman':'name','kirain':'i think','sya':'yes','pokoknya':'anyway','kok':'really','mantul':'really good','bangett':'really',\n",
    "'makasi':'thanks','dong':'please','sellernya':'seller','gak':'no','uda':'already','bangettt':'already','tetep':'still','pesenan':'order',\n",
    "'mudah2an':'i hope','smpai':'till','mah':'expensive','lgi':'again','lbh':'more','bagussss':'good','mantab':'steady','sukaa':'like',\n",
    "'jga':'also','bnget':'really','kaka':'written','meletot':'erupted','rdtanya' : 'he asked','chargernya':'charger','dsni':'here',\n",
    "'originalya':'original','jg':'too','deh':'okay','sdh':'already','tpi':'but','pokonya':'anyway','lah':'la','reallyt':'really',\n",
    "'sma':'school','orderan':'orders','wrna':'color','againi':'again','kak':'sis','rekomended':'recommended','kayak':'like',\n",
    "'blanja':'spend','likea':'like','becausea':'because','dlu':'previous','tau':'know','barang':'goods','dtng':'come','datang':'come',\n",
    "'bnyk': 'a lot','mantep':'awesome','swhich':'which','banget':'really','goodssss':'goods','rada':'rather','packagingnya':'packaging',\n",
    "'skrg':'now','pngiriman':'delivery','goodsss':'goods','prev':'previous','kan':'right','kek':'grandpa','lahh':'','lah':'','engga':'no',\n",
    "'makasih':'thank you','ordernya ':'orders','paketan':'package','mantapp':'really','ngecewain':'disappointed','pengirimanya':'sender',\n",
    "'bagus':'nice','comenya':'come','segini':'this much','knp':'why','bener':'right','kasi':'give','anak':'child','baik':'good','sukaa':'like',\n",
    "'likeaaa':'like','bangeet':'really','brgnya':'how come','ngk':'presume','lagi':'again','lagii':'again','hrg':'price','harga':'price',\n",
    "'penyok':'dent','penyok2':'dent','barangny':'goods','thanksi':'thanks','produk':'product','likeaaaaa':'like','murahhh':'cheap',\n",
    "'terimaksih':'thanks','ownernya':'owner','thankss':'thanks','gercep':'speed','casenya':'case','kakk':'sis','dteng':'come',\n",
    "'puasssss':'satisfied','masi':'still','sekali':'once','gapernah':'never','balikin':'return it','ancur':'broken','nyobain':'try it',\n",
    "'bangat':'really','nyangka':'suspect','sekalii':'once','sekaliii':'once','sekaliiii':'once','sampaii':'arrive','barangnyaa':'goods',\n",
    "'jaitannya':'linkage','nyari':'looking for it','bangeett':'really','disiniii':'here','abcdefghijklmnopqrstuvwxyz':'','priduk':'product',\n",
    "'baguuuuuuus':'nice','allhamdulilah':'','mantaffffffffffffffff':'excellent','sekaliiiii':'once','ambilis':'take it','parahhh':'severe','Ingkan':'want'}\n",
    "\n",
    "df_train = pd.read_csv('./Data/train.csv')\n",
    "df_test = pd.read_csv('./Data/test.csv')\n",
    "df_train.drop(['review_id'],axis = 1,inplace=True)\n",
    "df_train['rating'] = df_train['rating']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_of_caps(data):\n",
    "    count = 0\n",
    "    text = data.split(' ')\n",
    "    for each in text:\n",
    "        if each.isupper():\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def count_of_words(data):\n",
    "    cnt = 0\n",
    "    for text in data.split(' '):\n",
    "        cnt +=1\n",
    "    return cnt\n",
    "\n",
    "df_train['cap_count'] = df_train['review'].apply(lambda x : count_of_caps(x))\n",
    "df_train['word_count'] = df_train['review'].apply(lambda x: count_of_words(x))\n",
    "df_train['len'] = df_train['review'].str.len()\n",
    "\n",
    "df_test['cap_count'] = df_test['review'].apply(lambda x : count_of_caps(x))\n",
    "df_test['word_count'] = df_test['review'].apply(lambda x: count_of_words(x))\n",
    "df_test['len'] = df_test['review'].str.len()\n",
    "\n",
    "df_train = df_train[['review','cap_count','word_count','len','rating']]\n",
    "df_test = df_test[['review','cap_count','word_count','len']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def count_of_words_frame(data):\n",
    "    cnt = Counter()\n",
    "    for text in data:\n",
    "        for word in text.split():\n",
    "            cnt[word] +=1\n",
    "    return cnt\n",
    "\n",
    "train_count = count_of_words_frame(df_train['review'].str.lower())\n",
    "train_count = {k: v for k, v in sorted(train_count.items(), key=lambda item: item[1],reverse = True)}\n",
    "\n",
    "test_count = count_of_words_frame(df_test['review'].str.lower())\n",
    "test_count = {k: v for k, v in sorted(test_count.items(), key=lambda item: item[1],reverse = True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_emoticons(data):\n",
    "    for emot in EMOTICONS:\n",
    "        data = re.sub(u'('+emot+')',\" \".join(EMOTICONS[emot].replace(\",\",\"\").split()),data)        \n",
    "    return data\n",
    "\n",
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "# Removal of illegal characters\n",
    "df_train['review'] = df_train['review'].apply(lambda x: x.encode('ascii','ignore').decode('utf-8'))\n",
    "df_test['review'] = df_test['review'].apply(lambda x: x.encode('ascii','ignore').decode('utf-8'))\n",
    "\n",
    "df_train['review'] = df_train['review'].apply(lambda x: convert_emoticons(x))\n",
    "df_test['review'] = df_test['review'].apply(lambda x: convert_emoticons(x))\n",
    "\n",
    "df_train['review'] = df_train['review'].apply(lambda x: x.lower())\n",
    "df_test['review'] = df_test['review'].apply(lambda x: x.lower())\n",
    "\n",
    "df_train['review'] = df_train['review'].apply(lambda x : replace_all(x,mappings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def tokenize_stem(text):\n",
    "    doc = nltk.word_tokenize(text)\n",
    "    tokens = [w for w in doc if re.search('^[a-z]+$', w)]\n",
    "    clean = [w for w in tokens if w not in stopwords]    \n",
    "    final = [stemmer.stem(w) for w in clean] \n",
    "    return final\n",
    "\n",
    "df_train['tokens'] = df_train['review'].apply(lambda x : tokenize_stem(x))\n",
    "df_test['tokens'] = df_test['review'].apply(lambda x : tokenize_stem(x))\n",
    "\n",
    "tokens = df_train['tokens'].tolist()\n",
    "dictionary = gensim.corpora.Dictionary(tokens)\n",
    "dictionary.filter_extremes(no_below=10)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "tfidf = gensim.models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rating'] = df_train['rating'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val = train_test_split(df_train.iloc[:,:-1],df_train['rating'],test_size = 0.15,random_state = 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(min_df = 0.01,stop_words = stopwords)\n",
    "tfidf_train = vec.fit_transform(X_train['review'])\n",
    "\n",
    "tfidf_val = vec.transform(X_val['review'])\n",
    "tfidf_test = vec.transform(df_test['review'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_array_train = X_train[['cap_count','word_count','len']].values\n",
    "feat_array_val = X_val[['cap_count','word_count','len']].values\n",
    "feat_array_test = df_test[['cap_count','word_count','len']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feat_train = sparse.csr_matrix(feat_array_train)\n",
    "feats_train = sparse.hstack([tfidf_train,sparse_feat_train])\n",
    "\n",
    "sparse_feat_val = sparse.csr_matrix(feat_array_val)\n",
    "feats_val = sparse.hstack([tfidf_val,sparse_feat_val])\n",
    "\n",
    "sparse_feat_test = sparse.csr_matrix(feat_array_test)\n",
    "feats_test = sparse.hstack([tfidf_test,sparse_feat_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb = MultinomialNB()\n",
    "mb.fit(feats_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46433579882842235"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.score(feats_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124789, 977), (124789,), (22022, 977), (22022,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_train.shape,y_train.shape,feats_val.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44687131050767415"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_val,mb.predict(feats_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.predict(feats_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "voc_size = 12000\n",
    "\n",
    "one_hot_repr = [one_hot(words,voc_size) for words in df_train['review'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "sent_length = 20\n",
    "embedded_docs = pad_sequences(one_hot_repr,padding='pre',maxlen = sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(stopwords.words('english'))\n",
    "dim = 500\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
    "model.compile('adam','mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(embedded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.predict(embedded_docs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
